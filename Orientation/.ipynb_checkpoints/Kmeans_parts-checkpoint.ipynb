{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb3919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesh import Mesh\n",
    "#from gaussian_map_3 import Gaussian_Map\n",
    "from gaussian_map import Gaussian_Map\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Scitlearn  \n",
    "# from sklearn.cluster import MeanShift\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # Import Jan's label writer\n",
    "# import python_libs.write_labels_txt as jan\n",
    "\n",
    "\n",
    "# from plyfile import PlyData, PlyElement\n",
    "# import logging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1468c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/linsel/3931-6632/data/phd stone tools/Blades_Bladelets_PLY/annotated/coloured/selected/'\n",
    "\n",
    "name = '10361'#\"31.comp.1\"\n",
    "\n",
    "filename,quality_index = path + name + '.ply',3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd04555",
   "metadata": {},
   "source": [
    "# Mesh class:\n",
    "The Mesh class can be initialized using **Mesh()** . It has the following variables and functions:\n",
    "\n",
    "## Variables:\n",
    "- **Mesh.filename** filename as string. saved without .ply, but with folder structure\n",
    "\n",
    "- **Mesh.Vertices** Vertices stored as a dictionary of Vertex objects, keys are Vertex indices\n",
    "\n",
    "- **Mesh.Edges** Edges stored as a dictionary of Edge objects, keys are numbered\n",
    "\n",
    "- **Mesh.Faces** Faces stored as a dictionary of Face objects, keys are numbered\n",
    "\n",
    "- **Mesh.MorseComplex** if not calculated yet: None, otherwise a MorseComplex object with MorseComplex.persistence = 0\n",
    "\n",
    "- **Mesh.reducedMorseComplexes** a dictionary of MorseComplex objects, that have been reduced by a persistence parameter. The persistence parameter also defines the key of each MorseComplex object\n",
    "\n",
    "- **Mesh.MorseCells** a dictionary of MorseCells dictionaries. the key for each MorseCell dictionary is given by the persistence of the MorseComplex, these Cells were taken from. Each MorseCell dictionary consits of key, value pairs, where the key gives the label of a cell and the value is a set of vertices that make up this cell.\n",
    "\n",
    "## Functions:\n",
    "- **Mesh.load_mesh_ply(filename, quality_index)** loads a .ply file into the Mesh class and takes the value given at quality_index position as the scalar function on the vertices\n",
    "\n",
    "- **Mesh.info()** prints out Mesh info\n",
    "\n",
    "- **Mesh.ProcessLowerStars()** calculates the combinatorial gradient and critical simplices; **required for ExtractMorseComplex**\n",
    "\n",
    "- **Mesh.only_return_ExtractMorseComplex** return MorseComplex without storing it in the Mesh class\n",
    "\n",
    "- **Mesh.ExtractMorseComplex** calculate MorseComplex and store it in the Mesh class\n",
    "\n",
    "- **Mesh.only_return_ReducedMorseComplex(persistence)** reduce the MorseComplex based on the given persistence parameter, but dont store it in the Mesh class\n",
    "\n",
    "- **Mesh.ReducedMorseComplex(persistence)** reduce the MorseComplex based on the given persistence parameter, and store it in the Mesh class\n",
    "\n",
    "- **Mesh.plot_MorseComplex(MorseComplex, filename, path_color=[255,0,255])** plots the critical simplices of a MorseComplex in red (vertex), green (edge) and blue (face) and the according paths connecting them in magenta. Only writes a ply file containing colored points, so should be used as an overlay for the original mesh\n",
    "\n",
    "- **Mesh.ExtractMorseCells(MorseComplex)** takes a MorseComplex and gets all connected cells individually that are enclosed by the lines between critical simplices\n",
    "\n",
    "- **Mesh.plot_MorseCells(persistence, filename)** plots the connected components in each Cell in the same color. Only writes a ply file containing colored points, so should be used as an overlay for the original mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb42847b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time read data file: 5.096361181000248\n",
      "Time read and prepare data: 22.968083454998123\n"
     ]
    }
   ],
   "source": [
    "GM_1 = Gaussian_Map()\n",
    "GM_1.load_ply(filename, quality_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ef29ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time per run: 3.2235980559999007\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'GM_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m GM_1\u001b[38;5;241m.\u001b[39mcreate_point_cloud ()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mGM_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKmeans_oversegmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PhD/segmentation/Wang et al. 2013/Gaussian_Map/gaussian_map.py:402\u001b[0m, in \u001b[0;36mKmeans_oversegmentation\u001b[0;34m(self, depth)\u001b[0m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m label_list = GM_1.label_array[:,depth-1]\n\u001b[0;32m--> 402\u001b[0m for num,val in enumerate(np.sort(np.unique(GM_1.label_array[:,depth-1]))):\n\u001b[1;32m    403\u001b[0m     label_list[label_list == val] = int(num + 1)\n\u001b[1;32m    404\u001b[0m \n",
      "\u001b[0;31mNameError\u001b[0m: name 'GM_1' is not defined"
     ]
    }
   ],
   "source": [
    "GM_1.create_point_cloud ()\n",
    "GM_1.Kmeans_oversegmentation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b15e867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = GM_1.label_array[:,4]\n",
    "for num,val in enumerate(np.sort(np.unique(GM_1.label_array[:,4]))):\n",
    "    label_list[label_list == val] = int(num + 1)\n",
    "\n",
    "label_list =[int(x) for x in label_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc1308fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time writing label txt file: 0.11339926299842773\n"
     ]
    }
   ],
   "source": [
    "GM_1.export_labels(np.array(label_list),'output_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a26ba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time writing label txt file: 0.18085099701420404\n"
     ]
    }
   ],
   "source": [
    "GM_1.create_point_cloud ()\n",
    "GM_1.prep_orientate_mesh_pca ()\n",
    "GM_1.prep_orientate_mesh_Kmeans ()   \n",
    "GM_1.save_exp_cloud ()\n",
    "GM_1.export_exp_cloud_as_mesh ()\n",
    "GM_1.recalculate_normals ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b78cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud = [[value.x, value.y, value.z, value.quality, value.flags, \n",
    "                value.red, value.green, value.blue, value.nx, value.ny, \n",
    "                value.nz,value.phi, value.theta]  for value in GM_1.Vertices.values()]\n",
    "\n",
    "# variable_list = {1:'x',2:'y',3:'z', 4:'quality', 5:'flags', \n",
    "#              6:'red', 7:'green', 8:'blue', 9:'nx', 10:'ny', \n",
    "#              11:'nz', 12:'phi', 13:'theta'}\n",
    "\n",
    "variable_list = {'x':0,'y':1,'z':2, 'quality':3, 'flags':4, \n",
    "             'red':5, 'green':6, 'blue':7, 'nx':8, 'ny':9, \n",
    "             'nz':10, 'phi':11, 'theta':12}\n",
    "\n",
    "point_cloud = np.array (point_cloud)\n",
    "point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_pca(data, n_components):\n",
    "    # 1: Getting the mean and covariance\n",
    "    mean, cov = np.mean(data, axis=0), np.cov(data.T)\n",
    "\n",
    "    # 2: Compute eigenvectors and eigenvalues\n",
    "    vals, vecs = np.linalg.eig(cov)\n",
    "\n",
    "    # 3: Find the largest N eigenvalue indices\n",
    "    s = np.argsort(vals)[::-1][:n_components] \n",
    "    # Sorts smallest to largest, so we reverse it and then grab the top\n",
    "\n",
    "    # 4: Construct the transformation matrix\n",
    "    eigenvals = vals[s]\n",
    "    eigenvecs = vecs[:, s]\n",
    "    \n",
    "    print(eigenvals)\n",
    "\n",
    "    # 5: Apply the transformation\n",
    "    data_transformed = (data - mean) @ eigenvecs\n",
    "    return data_transformed, eigenvecs # returns transformed data and transformation matrix\n",
    "\n",
    "data_transformed,eigenvecs = manual_pca(point_cloud[:,:3], 3)\n",
    "\n",
    "# for i,value in enumerate(data_transformed):\n",
    "#     GM_1.Vertices[i].x = value[0]\n",
    "#     GM_1.Vertices[i].y = value[1]\n",
    "#     GM_1.Vertices[i].z = value[2]             \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f44b2",
   "metadata": {},
   "source": [
    "## Get principle axis for oriantation artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d6077a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "principalComponents = pca.fit_transform(point_cloud[:,:3])\n",
    "\n",
    "data_transformed = principalComponents\n",
    "\n",
    "# for i,value in enumerate(pca_1):\n",
    "#     print(value[0])\n",
    "#     GM_1.Vertices[i].x = value[0]\n",
    "#     GM_1.Vertices[i].y = value[1]\n",
    "#     GM_1.Vertices[i].z = value[2]             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede88743",
   "metadata": {},
   "source": [
    "## Get Front and back of artefact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f1c6691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time writing label txt file: 0.1793126449920237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "Normals = point_cloud[:,8:11]\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(Normals)\n",
    "klabels = kmeans.labels_\n",
    "\n",
    "import python_libs.write_labels_txt as jan\n",
    "\n",
    "labels = dict(enumerate(klabels.flatten(), 0))\n",
    "\n",
    "jan.write_labels_txt_file (labels,path + name + '_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b819e3",
   "metadata": {},
   "source": [
    "## Artefact reorientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2831c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate first the side with the higher overall curvature\n",
    "zero = np.sum(point_cloud[klabels == 0][:,4])/len(point_cloud[klabels == 0][:,4])\n",
    "one = np.sum(point_cloud[klabels == 1][:,4])/len(point_cloud[klabels == 1][:,4])\n",
    "y_sign = np.sign(np.sum(data_transformed[0])) # depends on the tool category \n",
    "if zero > one:\n",
    "    z_sign = np.sign(np.sum(principalComponents[klabels == 0]))\n",
    "    for i,value in enumerate(data_transformed):\n",
    "        GM_1.Vertices[i].x = value[1]\n",
    "        GM_1.Vertices[i].y = value[0] * y_sign\n",
    "        GM_1.Vertices[i].z = value[2] * z_sign\n",
    "elif zero < one:\n",
    "    z_sign = np.sign(np.sum(principalComponents[klabels == 1]))\n",
    "    for i,value in enumerate(data_transformed):\n",
    "        GM_1.Vertices[i].x = value[1]\n",
    "        GM_1.Vertices[i].y = value[0] * y_sign\n",
    "        GM_1.Vertices[i].z = value[2] * z_sign\n",
    "        \n",
    "exp_cloud = [[value.x, value.y, value.z, value.quality, value.flags, \n",
    "                value.red, value.green, value.blue, value.nx, value.ny, \n",
    "                value.nz,value.phi, value.theta]  for value in GM_1.Vertices.values()]\n",
    "\n",
    "exp_cloud = np.array (exp_cloud)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd77b27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.83647913, 18.51353342,  2.23885478, ..., -0.71474385,\n",
       "         0.43753254,  2.36705422],\n",
       "       [ 5.85255837, 24.56251209,  0.11886142, ..., -0.64679706,\n",
       "         0.49207559,  2.27417374],\n",
       "       [ 1.49071136, 12.32663455, -1.37351163, ...,  0.6724323 ,\n",
       "         0.25260159,  0.83330625],\n",
       "       ...,\n",
       "       [-3.18185786,  8.07595159,  3.59195808, ..., -0.60307962,\n",
       "        -0.57114655,  2.21815252],\n",
       "       [13.82318012, 13.34839867,  1.88386751, ..., -0.52973408,\n",
       "         0.55984294,  2.1290834 ],\n",
       "       [ 3.91213841, -4.90335759, -1.04165901, ...,  0.78694475,\n",
       "        -0.03272358,  0.66495472]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ba672b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'f4',\n",
       " 'y': 'f4',\n",
       " 'z': 'f4',\n",
       " 'quality': 'f4',\n",
       " 'flags': 'f4',\n",
       " 'red': 'uint8',\n",
       " 'green': 'uint8',\n",
       " 'blue': 'uint8',\n",
       " 'phi': 'f4',\n",
       " 'theta': 'f4'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tuple_List = (('x', 'f4'), ('y', 'f4'), ('z', 'f4'), ('quality', 'f4'),('flags', 'f4'),\n",
    "                              ('red', 'uint8'), ('green', 'uint8'), ('blue', 'uint8'), ('nx','f4'), \n",
    "                              ('ny','f4'),  ('nz','f4'), ('phi','f4'), ('theta','f4'))#, ('label', 'uint8'))\n",
    "\n",
    "Tuple_List = (('x', 'f4'), ('y', 'f4'), ('z', 'f4'), ('quality', 'f4'),('flags', 'f4'),\n",
    "                              ('red', 'uint8'), ('green', 'uint8'), ('blue', 'uint8'), ('phi','f4'), ('theta','f4'))#, ('label', 'uint8'))\n",
    "\n",
    "variable_list = {'x':0,'y':1,'z':2, 'quality':3, 'flags':4, \n",
    "             'red':5, 'green':6, 'blue':7, 'phi':11, 'theta':12}\n",
    "\n",
    "vertices_data_types = dict((i, j) for i, j in Tuple_List)\n",
    "\n",
    "vertices_data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c5d0168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0., 0., 0., 0., 0., 0, 0, 0, 0., 0., 0., 0., 0., 0),\n",
       "       (0., 0., 0., 0., 0., 0, 0, 0, 0., 0., 0., 0., 0., 0),\n",
       "       (0., 0., 0., 0., 0., 0, 0, 0, 0., 0., 0., 0., 0., 0), ...,\n",
       "       (0., 0., 0., 0., 0., 0, 0, 0, 0., 0., 0., 0., 0., 0),\n",
       "       (0., 0., 0., 0., 0., 0, 0, 0, 0., 0., 0., 0., 0., 0),\n",
       "       (0., 0., 0., 0., 0., 0, 0, 0, 0., 0., 0., 0., 0., 0)],\n",
       "      dtype=[('x', '<f4'), ('y', '<f4'), ('z', '<f4'), ('quality', '<f4'), ('flags', '<f4'), ('red', 'u1'), ('green', 'u1'), ('blue', 'u1'), ('nx', '<f4'), ('ny', '<f4'), ('nz', '<f4'), ('phi', '<f4'), ('theta', '<f4'), ('label', 'u1')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "437608c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0, 'y': 1, 'z': 2, 'quality': 3, 'flags': 4, 'red': 5, 'green': 6, 'blue': 7, 'phi': 11, 'theta': 12}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from plyfile import PlyData, PlyElement\n",
    "import logging\n",
    "\n",
    "# define 3D point cloud data\n",
    "n = exp_cloud.shape[0]\n",
    "\n",
    "# connect the proper data structures\n",
    "\n",
    "vertices = np.empty(n, dtype=list(Tuple_List))\n",
    "\n",
    "print(variable_list)\n",
    "for i in variable_list:\n",
    "\n",
    "    vertices[i] = exp_cloud[:,variable_list[i]].astype(vertices_data_types[i])\n",
    "\n",
    "\n",
    "#vertices['label'] = klabels.astype(vertices_data_types['label'])\n",
    "\n",
    "faces_building = []\n",
    "# for i in range(0, num_faces):\n",
    "for value in GM_1.Faces.values():\n",
    "    faces_building.append(((list(value.indices),)))\n",
    "faces = np.array(faces_building, dtype=[(\"vertex_indices\", \"i4\", (3,))])\n",
    "\n",
    "el_verts = PlyElement.describe(vertices, \"vertex\")\n",
    "el_faces = PlyElement.describe(faces, \"face\")\n",
    "\n",
    "\n",
    "# # save as ply\n",
    "ply_data = PlyData([el_verts, el_faces])\n",
    "ply_filename_out = path + name + \"_Kmeans_parted.ply\"\n",
    "logging.debug(\"saving mesh to %s\" % (ply_filename_out))\n",
    "ply_data.write(ply_filename_out)\n",
    "\n",
    "# ply = PlyData([PlyElement.describe(vertices, 'vertex')], text=False)\n",
    "# ply.write(ply_filename_out)\n",
    "# ply.write(path + name + '_back-' + str(bandwidth_back) + '_front-' + str(bandwidth_front) + \"_binary_meanshape-phitheta-maha_parted.ply\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb45f00",
   "metadata": {},
   "source": [
    "## Calculate new normal values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6ebd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "filename\n",
    "\n",
    "mesh = pv.read(path + name + \"_Kmeans_parted.ply\")\n",
    "\n",
    "mesh.compute_normals(inplace=True)  # this activates the normals as well\n",
    "\n",
    "mesh.save(path + name + '_Kmeans_parted_normals.ply')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c88df2",
   "metadata": {},
   "source": [
    "## Recursive Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f56373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3bf857",
   "metadata": {},
   "source": [
    "## Save Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2434b5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time writing label txt file: 0.062054529998931685\n"
     ]
    }
   ],
   "source": [
    "import python_libs.write_labels_txt as jan\n",
    "\n",
    "C_exp = dict(ridge_key)\n",
    "\n",
    "jan.write_labels_txt_file (C_exp,path + name + '_ridge')\n",
    "\n",
    "# pd.DataFrame(ridge_key)[pd.DataFrame(ridge_key)[1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d225b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
